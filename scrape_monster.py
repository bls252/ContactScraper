# $ python -c 'import scrape_monster; print scrape_monster.getNumberMonsterResultPages("sewing","california")'# based on Monster job listing site: https://www.monster.com/?disRe=trueimport requestsfrom bs4 import BeautifulSoup'''Helper function that takes the search URL from getMonsterResultURLs(skill, state) and returns the number of pagesthe search results fill up. Output is formatted as an int. '''def getNumberMonsterResultPages(skill, state):	firstPage = 'https://www.monster.com/jobs/search/?q=' + str(skill) + '&where=' + str(state)	#alternative for if you change the parameter to "url"	#firstPage = url	for i in range(1, 41):		search_url = firstPage + "&page=" + str(i)		r = requests.get(search_url)		soup = BeautifulSoup(r.content)		pageNotExist = soup.find_all("h4", text="We couldn't find this page for you")		if pageNotExist:			return i - 1'''Takes string inputs for "skill" and "state" and runs a search on monster.com for "skill" as a searchterm and limits results to that "state." Then it returns the URLs of each search result in a list.'''def getMonsterResultURLs(skill, state):	skill_keyword = str(skill) #make sure the inputs are strings	USstate = str(state)	search_url = "https://www.monster.com/jobs/search/?q=" + skill_keyword + "&where=" + USstate	NumberOfSearchablePages = getNumberMonsterResultPages(search_url)	resultList = list()	for i in range(0, NumberOfSearchablePages): #if we are on page zero, we are scraping the url page currently defined as search_url		if i == 0:			current_page_url = search_url		else:			current_page_url = search_url + "&page=" + str(i)		r = requests.get(current_page_url)		soup = BeautifulSoup(r.content)		result_divs = soup.find_all("div", {"class": "js_result_details-left"})		result_count = 0		for result in result_divs:			result_count += 1			job_title = result.contents[1].text # the name of the job position			company_name = result.contents[3].text # the name of the company			job_title_div = result.find_all("div", {"class":"jobTitle"})[0]			job_title_link = job_title_div.find_all("a")[0]			job_page_url = job_title_link.get("href")			resultList.append(job_page_url)	return resultList #returns all the job result urls in a list# _____________ Below is for the job page __________________#now we are working with the job's description page. It's URL will be from job_page_url# here is a list of things you have to check for once you open a job page:# Is the page an extension of "http://job-openings.monster.com/" or "https://jobs.veritude.com" or something else?# Is there a listing for salary?# If salary is listed, is it something obviously false like 1 dollar a year?# If the salary is listed, is it based on years or months? Standardize to per anum'''takes url of a job posting on monster.com and returns a double that is the estimated salary per year. If salary can't becalculated or is not listed, it returns a descriptive error in the form of a string.'''def getMonsterSalary(url):	#job_url = "http://job-openings.monster.com/Big-Data-Architect-will-relocate!!-Python-MongoDB-AWS-Dallas-TX-US-CyberCoders/11/185042119?MESCOID=1500142001001&jobPosition=2"	job_url = str(url) #check that the input is a string	if "monster" not in job_url:		return "Error: url does not lead to a monster.com native job posting."	jr = requests.get(job_url) # calls url	jsoup = BeautifulSoup(jr.content) # gets the inspect html code	job_sum_divs = jsoup.find_all("div", {"id": "JobSummary"})#searches for divs called "JobSummary", there should be only one	thing =  BeautifulSoup(str(job_sum_divs[0]), 'html.parser')#makes the JobSummary div parsable	if thing.find_all("h2", text="Salary"):# checks to see if there is a header for salary inside JobSummary, if not there's no listing for salary			flag = thing.find_all("h2", text="Salary")[0]			salaryTag = flag.findNext('h3') #the text of the salary is always stored in a h3 tag			salaryText = salaryTag.text #this is type unicode	else:		return "Error: This page does not have a salary listing" # should be replaced with a return statement	# now that we have the text of the salary, we are parsing it: 	#salaryText = "100,000.00 - 140,000.00 $  /year" # TAKE THIS OUT, only for testing purposes	salMin, salMax = salaryText.split("-")	#example of salMin right now: u'100,000.00 '	salMin = salMin.split()[0]# gets everything before the first space	salMin = salMin.replace(',', '')# removes comma	try:		salMin = float(salMin)	except:		return "Error: salary salMinimum could not be parsed because of irregular formatting"	# example of salMax right now: u' 140,000.00 $  /year'	# similar parsing process for salMax	salMax = salMax.split()[0]	salMax = salMax.replace(',', '')# removes comma	try:		salMax = float(salMax)	except:		return "Error: salary salMaximum could not be parsed because of irregular formatting"	# salMin and salMax are done, now we can define the period	period = "period has not been touched yet"	if "year" in salaryText:		period = "year"	elif "month" in salaryText:		period = "month"	elif "hour" in salaryText:		period = "hour"	else:		return "Error: Not sure what period to use to calculate salary. Example: period could be year, month, hour"	salaryDeliverable = 0.0	if salMin and salMax and isinstance(salMax, float) and isinstance(salMin, float):		if period == "year":			salaryDeliverable = (salMin + salMax)/2		elif period == "month":			salaryDeliverable = [(salMin + salMax)/2]*12		elif period == "hour":			salaryDeliverable = [(salMin + salMax)/2]*40*52		return salaryDeliverable	else:		return "Error: salMin and salMax could not be parsed into a float"# saved copy, delete this if other version works:# def getMonsterResultURLs(skill, state):# 	skill_keyword = str(skill) #make sure the inputs are strings# 	USstate = str(state)# 	search_url = "https://www.monster.com/jobs/search/?q=" + skill_keyword + "&where=" + USstate# 	search_url_page_2 = search_url + "&page=" + str(2)# 	r = requests.get(search_url)# 	soup = BeautifulSoup(r.content)# 	result_divs = soup.find_all("div", {"class": "js_result_details-left"})# 	result_count = 0# 	resultList = list()# 	for result in result_divs:# 		result_count += 1# 		job_title = result.contents[1].text # the name of the job position# 		company_name = result.contents[3].text # the name of the company# 		job_title_div = result.find_all("div", {"class":"jobTitle"})[0]# 		job_title_link = job_title_div.find_all("a")[0]# 		job_page_url = job_title_link.get("href")# 		resultList.append(job_page_url)# 	return resultList #returns all the job result urls in a list